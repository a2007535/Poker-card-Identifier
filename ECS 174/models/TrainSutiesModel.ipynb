{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\LALA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from pathlib import PurePath\n",
    "import cv2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input, BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Add\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'d': 1208, 's': 1202, 'h': 1198, 'c': 1176})\n",
      "Counter({'c': 318, 'h': 298, 'd': 291, 's': 289})\n"
     ]
    }
   ],
   "source": [
    "suites_images_train = np.load('../getDataSet/dataset/images_train.npy')\n",
    "suites_labels_train = np.load('../getDataSet/dataset/labels_train.npy')[:,1]\n",
    "suites_images_test = np.load('../getDataSet/dataset/images_test.npy')\n",
    "suites_labels_test = np.load('../getDataSet/dataset/labels_test.npy')[:,1]\n",
    "print(Counter(suites_labels_train))\n",
    "print(Counter(suites_labels_test))\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(suites_labels_train)\n",
    "suites_labels_train = le.transform(suites_labels_train)\n",
    "suites_labels_test = le.transform(suites_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\LALA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\LALA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 70, 70, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 70, 70, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 35, 35, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 35, 35, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 35, 35, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 35, 35, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 17, 17, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 17, 17, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 17, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 17, 17, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 8, 8, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 4, 4, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               262272    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 393540 (1.50 MB)\n",
      "Trainable params: 392964 (1.50 MB)\n",
      "Non-trainable params: 576 (2.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequential model\n",
    "suitesmodel = Sequential()\n",
    "\n",
    "# Add input layer\n",
    "suitesmodel.add(Input(shape=(70, 70, 1)))\n",
    "\n",
    "# Add first convolutional layer with batch normalization, pooling, and dropout\n",
    "suitesmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "suitesmodel.add(BatchNormalization())\n",
    "suitesmodel.add(MaxPooling2D((2, 2)))\n",
    "suitesmodel.add(Dropout(0.3))\n",
    "\n",
    "# Add second convolutional layer with batch normalization, pooling, and dropout\n",
    "suitesmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "suitesmodel.add(BatchNormalization())\n",
    "suitesmodel.add(MaxPooling2D((2, 2)))\n",
    "suitesmodel.add(Dropout(0.3))\n",
    "\n",
    "# Add third convolutional layer with batch normalization, pooling, and dropout\n",
    "suitesmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "suitesmodel.add(BatchNormalization())\n",
    "suitesmodel.add(MaxPooling2D((2, 2)))\n",
    "suitesmodel.add(Dropout(0.3))\n",
    "\n",
    "# Add fourth convolutional layer with batch normalization, pooling, and dropout\n",
    "suitesmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "suitesmodel.add(BatchNormalization())\n",
    "suitesmodel.add(MaxPooling2D((2, 2)))\n",
    "suitesmodel.add(Dropout(0.4))\n",
    "\n",
    "# Flatten the output and add dense layers\n",
    "suitesmodel.add(Flatten())\n",
    "suitesmodel.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "suitesmodel.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "suitesmodel.compile(optimizer=opt,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "suitesmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From c:\\Users\\LALA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\LALA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "75/75 [==============================] - 17s 198ms/step - loss: 1.8847 - accuracy: 0.2952 - val_loss: 3.0175 - val_accuracy: 0.2492\n",
      "Epoch 2/30\n",
      "75/75 [==============================] - 15s 194ms/step - loss: 1.3653 - accuracy: 0.4480 - val_loss: 3.1806 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "75/75 [==============================] - 14s 187ms/step - loss: 0.9805 - accuracy: 0.6135 - val_loss: 4.8347 - val_accuracy: 0.2659\n",
      "Epoch 4/30\n",
      "75/75 [==============================] - 14s 187ms/step - loss: 0.7742 - accuracy: 0.7172 - val_loss: 11.0929 - val_accuracy: 0.2659\n",
      "Epoch 5/30\n",
      "75/75 [==============================] - 14s 188ms/step - loss: 0.6427 - accuracy: 0.7751 - val_loss: 15.4427 - val_accuracy: 0.2659\n",
      "Epoch 6/30\n",
      "75/75 [==============================] - 14s 187ms/step - loss: 0.5461 - accuracy: 0.8223 - val_loss: 16.6100 - val_accuracy: 0.2667\n",
      "Epoch 7/30\n",
      "75/75 [==============================] - 14s 193ms/step - loss: 0.4722 - accuracy: 0.8641 - val_loss: 10.1322 - val_accuracy: 0.3278\n",
      "Epoch 8/30\n",
      "75/75 [==============================] - 15s 198ms/step - loss: 0.3953 - accuracy: 0.9034 - val_loss: 6.7665 - val_accuracy: 0.4992\n",
      "Epoch 9/30\n",
      "75/75 [==============================] - 14s 192ms/step - loss: 0.3103 - accuracy: 0.9398 - val_loss: 6.6644 - val_accuracy: 0.4314\n",
      "Epoch 10/30\n",
      "75/75 [==============================] - 14s 190ms/step - loss: 0.2759 - accuracy: 0.9477 - val_loss: 3.4466 - val_accuracy: 0.5084\n",
      "Epoch 11/30\n",
      "75/75 [==============================] - 16s 219ms/step - loss: 0.2279 - accuracy: 0.9645 - val_loss: 1.7866 - val_accuracy: 0.6773\n",
      "Epoch 12/30\n",
      "75/75 [==============================] - 18s 247ms/step - loss: 0.1948 - accuracy: 0.9732 - val_loss: 0.4456 - val_accuracy: 0.8896\n",
      "Epoch 13/30\n",
      "75/75 [==============================] - 15s 197ms/step - loss: 0.1674 - accuracy: 0.9812 - val_loss: 0.6588 - val_accuracy: 0.8361\n",
      "Epoch 14/30\n",
      "75/75 [==============================] - 16s 212ms/step - loss: 0.1608 - accuracy: 0.9816 - val_loss: 0.9792 - val_accuracy: 0.8052\n",
      "Epoch 15/30\n",
      "75/75 [==============================] - 16s 212ms/step - loss: 0.1400 - accuracy: 0.9856 - val_loss: 0.2322 - val_accuracy: 0.9599\n",
      "Epoch 16/30\n",
      "75/75 [==============================] - 16s 208ms/step - loss: 0.1249 - accuracy: 0.9872 - val_loss: 0.2151 - val_accuracy: 0.9615\n",
      "Epoch 17/30\n",
      "75/75 [==============================] - 16s 211ms/step - loss: 0.1136 - accuracy: 0.9889 - val_loss: 0.4914 - val_accuracy: 0.8721\n",
      "Epoch 18/30\n",
      "75/75 [==============================] - 16s 211ms/step - loss: 0.1066 - accuracy: 0.9916 - val_loss: 0.2051 - val_accuracy: 0.9565\n",
      "Epoch 19/30\n",
      "75/75 [==============================] - 16s 208ms/step - loss: 0.0903 - accuracy: 0.9946 - val_loss: 0.3236 - val_accuracy: 0.9164\n",
      "Epoch 20/30\n",
      "75/75 [==============================] - 16s 210ms/step - loss: 0.0860 - accuracy: 0.9935 - val_loss: 0.1654 - val_accuracy: 0.9691\n",
      "Epoch 21/30\n",
      "75/75 [==============================] - 15s 207ms/step - loss: 0.0816 - accuracy: 0.9939 - val_loss: 0.1630 - val_accuracy: 0.9732\n",
      "Epoch 22/30\n",
      "75/75 [==============================] - 17s 221ms/step - loss: 0.0823 - accuracy: 0.9929 - val_loss: 0.3705 - val_accuracy: 0.9181\n",
      "Epoch 23/30\n",
      "75/75 [==============================] - 15s 203ms/step - loss: 0.0691 - accuracy: 0.9954 - val_loss: 0.2793 - val_accuracy: 0.9239\n",
      "Epoch 24/30\n",
      "75/75 [==============================] - 15s 196ms/step - loss: 0.0621 - accuracy: 0.9964 - val_loss: 0.0812 - val_accuracy: 0.9925\n",
      "Epoch 25/30\n",
      "75/75 [==============================] - 14s 191ms/step - loss: 0.0597 - accuracy: 0.9954 - val_loss: 0.2694 - val_accuracy: 0.9406\n",
      "Epoch 26/30\n",
      "75/75 [==============================] - 15s 194ms/step - loss: 0.0628 - accuracy: 0.9933 - val_loss: 0.4208 - val_accuracy: 0.9214\n",
      "Epoch 27/30\n",
      "75/75 [==============================] - 15s 195ms/step - loss: 0.0527 - accuracy: 0.9964 - val_loss: 0.1536 - val_accuracy: 0.9707\n",
      "Epoch 28/30\n",
      "75/75 [==============================] - 15s 199ms/step - loss: 0.0474 - accuracy: 0.9975 - val_loss: 0.0432 - val_accuracy: 0.9992\n",
      "Epoch 29/30\n",
      "75/75 [==============================] - 17s 225ms/step - loss: 0.0485 - accuracy: 0.9958 - val_loss: 0.0416 - val_accuracy: 0.9992\n",
      "Epoch 30/30\n",
      "75/75 [==============================] - 16s 214ms/step - loss: 0.0596 - accuracy: 0.9916 - val_loss: 0.0534 - val_accuracy: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x215bb9efe90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suitesmodel.fit(suites_images_train, suites_labels_train,epochs=30, validation_data=(suites_images_test, suites_labels_test),batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "suitesmodel.save(\"./models/SuitesCNN.keras\")\n",
    "np.save('./encoders/SuitesEncoder.npy', le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
