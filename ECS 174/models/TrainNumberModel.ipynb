{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from pathlib import PurePath\n",
    "import cv2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input, BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Add\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'K': 379, 'A': 374, '5': 374, '3': 373, 'J': 373, 'Q': 372, '6': 371, 'T': 370, '2': 367, '4': 366, '9': 357, '8': 357, '7': 351})\n",
      "Counter({'7': 108, '8': 105, '9': 101, '4': 95, '2': 95, '6': 91, 'T': 90, '3': 87, 'J': 87, 'Q': 86, 'A': 85, '5': 85, 'K': 81})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "number_images_train = np.load('../getDataSet/dataset/images_train.npy')\n",
    "number_labels_train = np.load('../getDataSet/dataset/labels_train.npy')[:,0]\n",
    "number_images_test = np.load('../getDataSet/dataset/images_test.npy')\n",
    "number_labels_test = np.load('../getDataSet/dataset/labels_test.npy')[:,0]\n",
    "print(Counter(number_labels_train))\n",
    "print(Counter(number_labels_test))\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(number_labels_train)\n",
    "number_labels_train = le.transform(number_labels_train)\n",
    "number_labels_test = le.transform(number_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 70, 70, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 70, 70, 32)           320       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 35, 35, 32)           0         ['conv2d_4[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 35, 35, 32)           0         ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 35, 35, 64)           18496     ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 17, 17, 64)           0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 17, 17, 64)           0         ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 17, 17, 64)           36928     ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 17, 17, 64)           256       ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 17, 17, 64)           0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 17, 17, 64)           0         ['activation_2[0][0]',        \n",
      "                                                                     'dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 8, 8, 64)             0         ['add_2[0][0]']               \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 8, 8, 64)             0         ['max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 64)             36928     ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 8, 8, 64)             256       ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 8, 8, 64)             0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 8, 8, 64)             0         ['activation_3[0][0]',        \n",
      "                                                                     'dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 4, 4, 64)             0         ['add_3[0][0]']               \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 4, 4, 64)             0         ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 1024)                 0         ['dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  131200    ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 13)                   1677      ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 226061 (883.05 KB)\n",
      "Trainable params: 225805 (882.05 KB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Function to create a residual block\n",
    "def residual_block(x, filters, kernel_size=3, stride=1, activation='relu'):\n",
    "    shortcut = x\n",
    "    x = Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    return x\n",
    "\n",
    "# Create the model\n",
    "input_shape = (70, 70, 1)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Add the first residual block\n",
    "x = residual_block(x, 64)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Add the second residual block\n",
    "x = residual_block(x, 64)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(13, activation='softmax')(x)\n",
    "\n",
    "numbermodel = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# Compile the model\n",
    "opt = keras.optimizers.Adam()\n",
    "numbermodel.compile(optimizer=opt,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "numbermodel.summary()\n",
    "\n",
    "# # Create the Sequential model\n",
    "# numbermodel = Sequential()\n",
    "\n",
    "# # Add input layer\n",
    "# numbermodel.add(Input(shape=(70, 70, 1)))\n",
    "\n",
    "# # Add convolutional, batch normalization, pooling, and dropout layers\n",
    "# numbermodel.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "# numbermodel.add(BatchNormalization())\n",
    "# numbermodel.add(MaxPooling2D((2, 2)))\n",
    "# numbermodel.add(Dropout(0.3))\n",
    "\n",
    "# numbermodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# numbermodel.add(BatchNormalization())\n",
    "# numbermodel.add(MaxPooling2D((2, 2)))\n",
    "# numbermodel.add(Dropout(0.3))\n",
    "\n",
    "# numbermodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# numbermodel.add(BatchNormalization())\n",
    "# numbermodel.add(MaxPooling2D((2, 2)))\n",
    "# numbermodel.add(Dropout(0.3))\n",
    "\n",
    "# numbermodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "# numbermodel.add(BatchNormalization())\n",
    "# numbermodel.add(MaxPooling2D((2, 2)))\n",
    "# numbermodel.add(Dropout(0.4))\n",
    "\n",
    "# # Flatten the output and add dense layers\n",
    "# numbermodel.add(Flatten())\n",
    "# numbermodel.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "# numbermodel.add(Dense(13, activation='softmax'))\n",
    "\n",
    "# # Compile the model\n",
    "# opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "# numbermodel.compile(optimizer=opt,\n",
    "#                     loss='sparse_categorical_crossentropy',\n",
    "#                     metrics=['accuracy'])\n",
    "\n",
    "# # Print the model summary\n",
    "# numbermodel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\LALA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\LALA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "75/75 [==============================] - 12s 128ms/step - loss: 2.7456 - accuracy: 0.1089 - val_loss: 2.5598 - val_accuracy: 0.0903\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 10s 127ms/step - loss: 2.4200 - accuracy: 0.1384 - val_loss: 2.5703 - val_accuracy: 0.0711\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 10s 133ms/step - loss: 2.2184 - accuracy: 0.2084 - val_loss: 2.5064 - val_accuracy: 0.1095\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 9s 125ms/step - loss: 1.9555 - accuracy: 0.2993 - val_loss: 2.5582 - val_accuracy: 0.1254\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 10s 130ms/step - loss: 1.5948 - accuracy: 0.4264 - val_loss: 2.3084 - val_accuracy: 0.1848\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 10s 130ms/step - loss: 1.2704 - accuracy: 0.5299 - val_loss: 2.1442 - val_accuracy: 0.1781\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 11s 142ms/step - loss: 0.8949 - accuracy: 0.6946 - val_loss: 2.9265 - val_accuracy: 0.1689\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 9s 124ms/step - loss: 0.5819 - accuracy: 0.8083 - val_loss: 1.4735 - val_accuracy: 0.4666\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 9s 124ms/step - loss: 0.3468 - accuracy: 0.8953 - val_loss: 1.1012 - val_accuracy: 0.5861\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 9s 123ms/step - loss: 0.2017 - accuracy: 0.9396 - val_loss: 0.8467 - val_accuracy: 0.6923\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 9s 123ms/step - loss: 0.1274 - accuracy: 0.9628 - val_loss: 1.3198 - val_accuracy: 0.6254\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 9s 120ms/step - loss: 0.0821 - accuracy: 0.9812 - val_loss: 0.7910 - val_accuracy: 0.7174\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 9s 120ms/step - loss: 0.0628 - accuracy: 0.9827 - val_loss: 0.2666 - val_accuracy: 0.8963\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 10s 129ms/step - loss: 0.0507 - accuracy: 0.9864 - val_loss: 0.2104 - val_accuracy: 0.9331\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 9s 125ms/step - loss: 0.0354 - accuracy: 0.9910 - val_loss: 0.0804 - val_accuracy: 0.9783\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 9s 126ms/step - loss: 0.0248 - accuracy: 0.9956 - val_loss: 0.0900 - val_accuracy: 0.9724\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 10s 132ms/step - loss: 0.0298 - accuracy: 0.9931 - val_loss: 0.4329 - val_accuracy: 0.8495\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 10s 137ms/step - loss: 0.0150 - accuracy: 0.9967 - val_loss: 0.0437 - val_accuracy: 0.9866\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 10s 132ms/step - loss: 0.0183 - accuracy: 0.9956 - val_loss: 0.0590 - val_accuracy: 0.9841\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 10s 132ms/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.0911 - val_accuracy: 0.9732\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 10s 129ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.0413 - val_accuracy: 0.9883\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 10s 138ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0380 - val_accuracy: 0.9875\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 10s 140ms/step - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.0376 - val_accuracy: 0.9875\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 11s 143ms/step - loss: 0.0161 - accuracy: 0.9967 - val_loss: 0.5289 - val_accuracy: 0.8554\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 10s 137ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.1230 - val_accuracy: 0.9599\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 11s 141ms/step - loss: 0.0247 - accuracy: 0.9939 - val_loss: 0.0660 - val_accuracy: 0.9783\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 10s 136ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.0871 - val_accuracy: 0.9766\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 10s 134ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.1977 - val_accuracy: 0.9314\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 10s 136ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.0223 - val_accuracy: 0.9950\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 10s 138ms/step - loss: 0.0304 - accuracy: 0.9906 - val_loss: 0.3164 - val_accuracy: 0.8963\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 9s 125ms/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.2663 - val_accuracy: 0.9181\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 9s 125ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0240 - val_accuracy: 0.9933\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 10s 132ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0290 - val_accuracy: 0.9908\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 10s 127ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0435 - val_accuracy: 0.9883\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 9s 125ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0529 - val_accuracy: 0.9816\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 9s 125ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0472 - val_accuracy: 0.9875\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 10s 130ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.1381 - val_accuracy: 0.9557\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 9s 125ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0279 - val_accuracy: 0.9941\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 9s 124ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.1758 - val_accuracy: 0.9457\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 9s 124ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.1178 - val_accuracy: 0.9640\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 11s 150ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.0368 - val_accuracy: 0.9916\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 10s 127ms/step - loss: 0.0252 - accuracy: 0.9925 - val_loss: 0.0969 - val_accuracy: 0.9774\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 9s 125ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.0392 - val_accuracy: 0.9900\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 9s 124ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.0272 - val_accuracy: 0.9941\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 10s 128ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0226 - val_accuracy: 0.9941\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 9s 125ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 1.4764 - val_accuracy: 0.7107\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 9s 124ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.2912 - val_accuracy: 0.9247\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 9s 125ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.6411 - val_accuracy: 0.8495\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 9s 126ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.1283 - val_accuracy: 0.9615\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 9s 125ms/step - loss: 0.0185 - accuracy: 0.9929 - val_loss: 0.0188 - val_accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x133ea048f10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbermodel.fit(number_images_train, number_labels_train,epochs=50, validation_data=(number_images_test, number_labels_test),batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbermodel.save(\"./models/NumberResCNN.keras\")\n",
    "np.save('./encoders/NumberEncoder.npy', le.classes_)\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.classes_ =  np.load('classes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
